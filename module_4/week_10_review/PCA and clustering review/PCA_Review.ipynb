{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA is solving the equation ùê¥ùë•‚Éó =ùúÜùë•‚Éó , for some scalar ùúÜ.  Another way of writing this equation to make the linear algebra clearer is (ùê¥‚àíùúÜùêº)ùë•‚Éó =0\n",
    "\n",
    "IOW: \"What is the set of vectors which, when I multiply them by my matrix of data, results in that same set of vectors just moved in space by a scalar distance\"\n",
    "\n",
    "The idea is that we want to transform our data into a set of mutually-orthoganal vectors which still capture most of the linear variance in the data.  Why?\n",
    "\n",
    "- Dimensionally reduction.  As dimensions increase, observations get further apart and distance calculations, which a lot of techinuqes rely on, get less effective.  Picture trying to cluster 100 data points in 2 dimensions.  Now picture clustering 100 pts in 500.  By reducing dimensions, we're able to avoid the complications that come with spreading points further and further out.  \n",
    "\n",
    "- By making the features in our data orthogonal, we're ensuring that values for observations in one dimension aren't dependent on information in another dimension.  This is a large advantage in constructing models, since information in a given feature is soley about that feature, and not incorporating information from other features; models have an easier time distinguishing what information is coming from which feature.  (Think back to regression and why multicollinearity is a problem.) When we go to predict off of orthogonal features, our techniques are able to make better predictions.  \n",
    "\n",
    "ùë•‚Éó is a matrix of \"eigenvectors\", which we interpret as \"principal components\", the vectors along which there is linear variance in the data.  \n",
    "\n",
    "The first principal component is the vector along which the data varies the most.  The second principal component is the vector along which the data varies the second most and is orthogonal to the first component.  The third princpal component is the vector along which the data varies third most and is orthogonal to the first two, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![pca](img/pca.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eigenvalues, ùúÜ, are stored in a matrix, the diagonal of which contain the eigenvalues: the specific values which apply to the equation in the first line. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "med = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760          0.3001              0.14710         0.2419   \n",
       "1           0.07864          0.0869              0.07017         0.1812   \n",
       "2           0.15990          0.1974              0.12790         0.2069   \n",
       "3           0.28390          0.2414              0.10520         0.2597   \n",
       "4           0.13280          0.1980              0.10430         0.1809   \n",
       "\n",
       "   mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                 0.07871  ...          17.33           184.60      2019.0   \n",
       "1                 0.05667  ...          23.41           158.80      1956.0   \n",
       "2                 0.05999  ...          25.53           152.50      1709.0   \n",
       "3                 0.09744  ...          26.50            98.87       567.7   \n",
       "4                 0.05883  ...          16.67           152.20      1575.0   \n",
       "\n",
       "   worst smoothness  worst compactness  worst concavity  worst concave points  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   worst symmetry  worst fractal dimension  Target  \n",
       "0          0.4601                  0.11890       0  \n",
       "1          0.2750                  0.08902       0  \n",
       "2          0.3613                  0.08758       0  \n",
       "3          0.6638                  0.17300       0  \n",
       "4          0.2364                  0.07678       0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = med.data\n",
    "y = med.target\n",
    "columns = med.feature_names\n",
    "df = pd.DataFrame(X)\n",
    "df.columns = columns\n",
    "df['Target'] = y\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a demonstration of the power of PCA, let's only use a subset of this dataset for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, random_state=666\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "X_test = pd.DataFrame(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_reduce = X_train.iloc[:, [x for x in range(0,10)]]\n",
    "X_test_reduce = X_test.iloc[:, [x for x in range(0,10)]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a PCA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.99053793e+00, -1.70143967e+00, -2.47597397e-01,\n",
       "         1.47112470e-01,  1.93148609e-01,  1.26430575e-02,\n",
       "         6.84490107e-02,  1.22296147e-01, -7.67397537e-02,\n",
       "        -2.66818546e-03],\n",
       "       [-7.63064730e-01,  1.11867073e-01, -7.83578371e-01,\n",
       "         1.71429573e-01,  2.92828059e-01,  2.66144861e-01,\n",
       "         1.34270451e-01,  1.82316074e-01, -9.04842935e-02,\n",
       "         1.22503707e-02],\n",
       "       [-1.26847786e+00, -2.25054068e+00,  1.85928194e+00,\n",
       "         6.29731566e-01,  4.06740285e-01, -1.05887082e-01,\n",
       "         1.44728864e-02,  6.24524220e-02, -7.83116799e-02,\n",
       "         3.78208270e-03],\n",
       "       [-1.79707915e+00,  6.00103394e-01, -1.21427501e+00,\n",
       "         5.08872029e-02, -1.20241649e-01,  1.60625908e-01,\n",
       "        -4.25335614e-02, -1.06401046e-01,  6.49602012e-02,\n",
       "        -4.95611384e-04],\n",
       "       [-2.10405333e+00, -9.68323155e-01, -6.55193987e-01,\n",
       "         1.12438700e-01,  1.04281049e-01, -3.82307884e-01,\n",
       "        -4.72516804e-02,  2.51976937e-01, -6.55108712e-02,\n",
       "         4.33344294e-03],\n",
       "       [-2.49656376e+00, -4.57371020e-01, -6.55051907e-01,\n",
       "         1.32081604e-01,  1.27332582e+00,  2.45918117e-01,\n",
       "         4.00214095e-02, -8.66938967e-02,  5.08364676e-02,\n",
       "         6.70954561e-03],\n",
       "       [-9.61854001e-01,  5.50425287e-03,  1.27051511e+00,\n",
       "        -1.60492358e+00,  3.35239055e-02,  5.56466244e-01,\n",
       "         6.92517228e-02, -5.59539819e-02,  1.05926295e-02,\n",
       "        -9.18781629e-03],\n",
       "       [-2.31457171e+00,  1.64968311e+00, -1.15663411e+00,\n",
       "        -1.32068480e-01, -1.15432273e-01, -3.17336426e-02,\n",
       "         3.92824693e-01, -1.19645232e-01,  9.28152881e-02,\n",
       "         7.13418000e-03],\n",
       "       [-5.23295145e-01, -1.49548422e+00,  4.25982334e-01,\n",
       "        -6.02259473e-02, -3.84042413e-01, -7.65935083e-02,\n",
       "         1.18527207e-02,  1.30909433e-01, -8.92443859e-02,\n",
       "         6.81846601e-04],\n",
       "       [ 2.92244539e+00,  1.77141741e+00,  5.99470775e-01,\n",
       "        -2.71527908e-01, -5.95207150e-02,  3.68128447e-02,\n",
       "         2.50769075e-01,  4.42090380e-02, -1.85337078e-01,\n",
       "         1.81640990e-02]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "pca = PCA(n_components=10)\n",
    "\n",
    "X_train_red_sc = ss.fit_transform(X_train_reduce)\n",
    "X_test_red_sc = ss.transform(X_test_reduce)\n",
    "\n",
    "X_train_red_sc_pca = pca.fit_transform(X_train_red_sc)\n",
    "X_test_red_sc_pca = pca.transform(X_test_red_sc)\n",
    "\n",
    "X_train_red_sc_pca[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting the Explained Variance of the Principal Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember that PCA decomposes the original dataset into principal components which attempt to encapsulate the maximum amount of information as defined by the maximum variance across observations. With this, it is useful to investigate how much variance in the dataset is accounted for in the first $n$ components. \n",
    "\n",
    "While you will have the same number of principal components as you have original features to account for all of the variance in a dataset (assuming you don't have redundant features), the first few principal components will typically account for the vast majority of the variance.\n",
    "\n",
    "sci-kit learn makes this very easy using the expalined_variance_ratio_ attribute of the instantiated PCA model object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.44962598e-01, 2.47715572e-01, 8.93516414e-02, 5.28058038e-02,\n",
       "       3.93907594e-02, 1.21594806e-02, 8.61669610e-03, 3.73925749e-03,\n",
       "       1.23093317e-03, 2.72580647e-05])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5449626 , 0.79267817, 0.88202981, 0.93483562, 0.97422637,\n",
       "       0.98638586, 0.99500255, 0.99874181, 0.99997274, 1.        ])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_.cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we can grab a lot of linear variance in the data with only the first four components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_red_sc_pca = pd.DataFrame(X_train_red_sc_pca)\n",
    "X_train_red_sc_pca_4 = X_train_red_sc_pca.iloc[:, 0:5]\n",
    "\n",
    "X_test_red_sc_pca = pd.DataFrame(X_test_red_sc_pca)\n",
    "X_test_red_sc_pca_4 = X_test_red_sc_pca.iloc[:, 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA rubber-to-the-road metric comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90        56\n",
      "           1       0.95      0.92      0.94        87\n",
      "\n",
      "    accuracy                           0.92       143\n",
      "   macro avg       0.92      0.92      0.92       143\n",
      "weighted avg       0.92      0.92      0.92       143\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.93      0.90        56\n",
      "           1       0.95      0.92      0.94        87\n",
      "\n",
      "    accuracy                           0.92       143\n",
      "   macro avg       0.92      0.92      0.92       143\n",
      "weighted avg       0.92      0.92      0.92       143\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "knn_pca = KNeighborsClassifier()\n",
    "\n",
    "knn.fit(X_train_red_sc, y_train)\n",
    "preds = knn.predict(X_test_red_sc)\n",
    "\n",
    "knn_pca.fit(X_train_red_sc_pca_4, y_train)\n",
    "preds_pca = knn_pca.predict(X_test_red_sc_pca_4)\n",
    "\n",
    "print(classification_report(y_test, preds))\n",
    "print(classification_report(y_test, preds_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For the interested, here's how to calculate principal components manually\n",
    "\n",
    "What follows is indebted to Sebastian Raschka (http://sebastianraschka.com/Articles/2015_pca_in_3_steps.html#pca-vs-lda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PC1</th>\n",
       "      <th>PC2</th>\n",
       "      <th>PC3</th>\n",
       "      <th>PC4</th>\n",
       "      <th>PC5</th>\n",
       "      <th>PC6</th>\n",
       "      <th>PC7</th>\n",
       "      <th>PC8</th>\n",
       "      <th>PC9</th>\n",
       "      <th>PC10</th>\n",
       "      <th>...</th>\n",
       "      <th>PC21</th>\n",
       "      <th>PC22</th>\n",
       "      <th>PC23</th>\n",
       "      <th>PC24</th>\n",
       "      <th>PC25</th>\n",
       "      <th>PC26</th>\n",
       "      <th>PC27</th>\n",
       "      <th>PC28</th>\n",
       "      <th>PC29</th>\n",
       "      <th>PC30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1160.142574</td>\n",
       "      <td>-293.917544</td>\n",
       "      <td>48.578398</td>\n",
       "      <td>-8.711975</td>\n",
       "      <td>32.000486</td>\n",
       "      <td>1.265415</td>\n",
       "      <td>0.931337</td>\n",
       "      <td>0.148167</td>\n",
       "      <td>0.745463</td>\n",
       "      <td>0.589359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021189</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>0.011560</td>\n",
       "      <td>0.005773</td>\n",
       "      <td>0.001377</td>\n",
       "      <td>-0.001982</td>\n",
       "      <td>0.001293</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>0.000704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1269.122443</td>\n",
       "      <td>15.630182</td>\n",
       "      <td>-35.394534</td>\n",
       "      <td>17.861283</td>\n",
       "      <td>-4.334874</td>\n",
       "      <td>-0.225872</td>\n",
       "      <td>-0.046037</td>\n",
       "      <td>0.200804</td>\n",
       "      <td>-0.485828</td>\n",
       "      <td>-0.084035</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005237</td>\n",
       "      <td>0.021069</td>\n",
       "      <td>0.001565</td>\n",
       "      <td>0.006968</td>\n",
       "      <td>-0.006978</td>\n",
       "      <td>0.001411</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>-0.001347</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>-0.001061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>995.793889</td>\n",
       "      <td>39.156743</td>\n",
       "      <td>-1.709753</td>\n",
       "      <td>4.199340</td>\n",
       "      <td>-0.466529</td>\n",
       "      <td>-2.652811</td>\n",
       "      <td>-0.779745</td>\n",
       "      <td>-0.274026</td>\n",
       "      <td>-0.173874</td>\n",
       "      <td>-0.186994</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009865</td>\n",
       "      <td>-0.002394</td>\n",
       "      <td>-0.004125</td>\n",
       "      <td>-0.004007</td>\n",
       "      <td>0.000709</td>\n",
       "      <td>-0.003781</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>-0.000775</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>-407.180803</td>\n",
       "      <td>-67.380320</td>\n",
       "      <td>8.672848</td>\n",
       "      <td>-11.759867</td>\n",
       "      <td>7.115461</td>\n",
       "      <td>1.299436</td>\n",
       "      <td>-1.267304</td>\n",
       "      <td>-0.060555</td>\n",
       "      <td>-0.330639</td>\n",
       "      <td>-0.144155</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011169</td>\n",
       "      <td>0.007063</td>\n",
       "      <td>0.001537</td>\n",
       "      <td>0.007003</td>\n",
       "      <td>-0.010261</td>\n",
       "      <td>-0.002899</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>-0.002139</td>\n",
       "      <td>-0.001657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>930.341180</td>\n",
       "      <td>189.340742</td>\n",
       "      <td>1.374801</td>\n",
       "      <td>8.499183</td>\n",
       "      <td>7.613289</td>\n",
       "      <td>1.021160</td>\n",
       "      <td>-0.335522</td>\n",
       "      <td>0.289109</td>\n",
       "      <td>0.036087</td>\n",
       "      <td>-0.138502</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009916</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.002204</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.002455</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.000327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>1414.126684</td>\n",
       "      <td>110.222492</td>\n",
       "      <td>40.065944</td>\n",
       "      <td>6.562240</td>\n",
       "      <td>-5.102856</td>\n",
       "      <td>-0.395424</td>\n",
       "      <td>-0.786751</td>\n",
       "      <td>0.037082</td>\n",
       "      <td>-0.452530</td>\n",
       "      <td>-0.235185</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.017214</td>\n",
       "      <td>0.007864</td>\n",
       "      <td>-0.002317</td>\n",
       "      <td>-0.002384</td>\n",
       "      <td>-0.003637</td>\n",
       "      <td>-0.008211</td>\n",
       "      <td>0.002418</td>\n",
       "      <td>0.001234</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>1045.018854</td>\n",
       "      <td>77.057589</td>\n",
       "      <td>0.036669</td>\n",
       "      <td>-4.753245</td>\n",
       "      <td>-12.417863</td>\n",
       "      <td>-0.059637</td>\n",
       "      <td>0.449831</td>\n",
       "      <td>0.509154</td>\n",
       "      <td>-0.449986</td>\n",
       "      <td>0.493247</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011219</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>-0.003028</td>\n",
       "      <td>-0.007931</td>\n",
       "      <td>0.002905</td>\n",
       "      <td>-0.002519</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>-0.000621</td>\n",
       "      <td>-0.000741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>314.501756</td>\n",
       "      <td>47.553525</td>\n",
       "      <td>-10.442407</td>\n",
       "      <td>-9.771881</td>\n",
       "      <td>-6.156213</td>\n",
       "      <td>-0.870726</td>\n",
       "      <td>-2.166493</td>\n",
       "      <td>-0.442279</td>\n",
       "      <td>-0.097398</td>\n",
       "      <td>-0.144667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003362</td>\n",
       "      <td>-0.002249</td>\n",
       "      <td>-0.001248</td>\n",
       "      <td>-0.003927</td>\n",
       "      <td>-0.000921</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>-0.001325</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>-0.000285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>1124.858115</td>\n",
       "      <td>34.129225</td>\n",
       "      <td>-19.742087</td>\n",
       "      <td>-23.660881</td>\n",
       "      <td>3.565133</td>\n",
       "      <td>4.086390</td>\n",
       "      <td>-1.705401</td>\n",
       "      <td>-0.359964</td>\n",
       "      <td>0.385030</td>\n",
       "      <td>0.615467</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006130</td>\n",
       "      <td>-0.010804</td>\n",
       "      <td>0.005841</td>\n",
       "      <td>0.001127</td>\n",
       "      <td>-0.002646</td>\n",
       "      <td>0.001862</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>0.001235</td>\n",
       "      <td>-0.000809</td>\n",
       "      <td>0.001217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>-771.527622</td>\n",
       "      <td>-88.643106</td>\n",
       "      <td>23.889032</td>\n",
       "      <td>2.547249</td>\n",
       "      <td>-14.717566</td>\n",
       "      <td>4.418123</td>\n",
       "      <td>-2.815752</td>\n",
       "      <td>0.030039</td>\n",
       "      <td>-0.423451</td>\n",
       "      <td>-0.301439</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018435</td>\n",
       "      <td>-0.009224</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.011529</td>\n",
       "      <td>0.012745</td>\n",
       "      <td>0.003539</td>\n",
       "      <td>0.001129</td>\n",
       "      <td>-0.004446</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.001468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             PC1         PC2        PC3        PC4        PC5       PC6  \\\n",
       "0    1160.142574 -293.917544  48.578398  -8.711975  32.000486  1.265415   \n",
       "1    1269.122443   15.630182 -35.394534  17.861283  -4.334874 -0.225872   \n",
       "2     995.793889   39.156743  -1.709753   4.199340  -0.466529 -2.652811   \n",
       "3    -407.180803  -67.380320   8.672848 -11.759867   7.115461  1.299436   \n",
       "4     930.341180  189.340742   1.374801   8.499183   7.613289  1.021160   \n",
       "..           ...         ...        ...        ...        ...       ...   \n",
       "564  1414.126684  110.222492  40.065944   6.562240  -5.102856 -0.395424   \n",
       "565  1045.018854   77.057589   0.036669  -4.753245 -12.417863 -0.059637   \n",
       "566   314.501756   47.553525 -10.442407  -9.771881  -6.156213 -0.870726   \n",
       "567  1124.858115   34.129225 -19.742087 -23.660881   3.565133  4.086390   \n",
       "568  -771.527622  -88.643106  23.889032   2.547249 -14.717566  4.418123   \n",
       "\n",
       "          PC7       PC8       PC9      PC10  ...      PC21      PC22  \\\n",
       "0    0.931337  0.148167  0.745463  0.589359  ...  0.021189  0.000241   \n",
       "1   -0.046037  0.200804 -0.485828 -0.084035  ...  0.005237  0.021069   \n",
       "2   -0.779745 -0.274026 -0.173874 -0.186994  ... -0.009865 -0.002394   \n",
       "3   -1.267304 -0.060555 -0.330639 -0.144155  ...  0.011169  0.007063   \n",
       "4   -0.335522  0.289109  0.036087 -0.138502  ... -0.009916  0.010269   \n",
       "..        ...       ...       ...       ...  ...       ...       ...   \n",
       "564 -0.786751  0.037082 -0.452530 -0.235185  ... -0.017214  0.007864   \n",
       "565  0.449831  0.509154 -0.449986  0.493247  ...  0.011219 -0.001905   \n",
       "566 -2.166493 -0.442279 -0.097398 -0.144667  ... -0.003362 -0.002249   \n",
       "567 -1.705401 -0.359964  0.385030  0.615467  ... -0.006130 -0.010804   \n",
       "568 -2.815752  0.030039 -0.423451 -0.301439  ...  0.018435 -0.009224   \n",
       "\n",
       "         PC23      PC24      PC25      PC26      PC27      PC28      PC29  \\\n",
       "0    0.002528  0.011560  0.005773  0.001377 -0.001982  0.001293  0.001989   \n",
       "1    0.001565  0.006968 -0.006978  0.001411 -0.000083 -0.001347  0.000686   \n",
       "2   -0.004125 -0.004007  0.000709 -0.003781  0.000178  0.000018 -0.000775   \n",
       "3    0.001537  0.007003 -0.010261 -0.002899  0.000016  0.001369 -0.002139   \n",
       "4    0.002204  0.002764  0.002455  0.001665  0.003290  0.000273  0.001783   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "564 -0.002317 -0.002384 -0.003637 -0.008211  0.002418  0.001234 -0.000078   \n",
       "565 -0.003028 -0.007931  0.002905 -0.002519  0.000212  0.001006 -0.000621   \n",
       "566 -0.001248 -0.003927 -0.000921  0.000573 -0.001325  0.000025  0.000484   \n",
       "567  0.005841  0.001127 -0.002646  0.001862  0.002698  0.001235 -0.000809   \n",
       "568  0.000242  0.011529  0.012745  0.003539  0.001129 -0.004446  0.000243   \n",
       "\n",
       "         PC30  \n",
       "0    0.000704  \n",
       "1   -0.001061  \n",
       "2    0.000405  \n",
       "3   -0.001657  \n",
       "4    0.000327  \n",
       "..        ...  \n",
       "564 -0.000455  \n",
       "565 -0.000741  \n",
       "566 -0.000285  \n",
       "567  0.001217  \n",
       "568  0.001468  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll start by producing the covariance matrix for the columns of X_tr_sc.\n",
    "\n",
    "cov_mat = np.cov(X_scaled, rowvar=False)\n",
    "cov_mat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.eig(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assign the results of eig(cov_mat) to a double of variables.\n",
    "\n",
    "eigvals, eigvecs = np.linalg.eig(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The columns of \"eigvecs\" are the eigenvectors!\n",
    "\n",
    "eigvecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The eigenvectors of the covariance matrix are our principal components.\n",
    "# Let's look at the first three.\n",
    "\n",
    "pcabh = np.vstack([row[:3].reshape(1, 3) for row in eigvecs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to transform our data points into the space defined by the principal components, we simply need to compute the dot-product of X_scaled with those principal components.\n",
    "\n",
    "Why? Think about what this matrix product looks like:\n",
    "\n",
    "We take a row of X_scaled and multiply it by a column of pcabh, pairwise. The row of X_scaled represents the values for the columns in the original space. The column of pcabh represents the weights we need on each of the original columns in order to transform a value into principal-component space. And so the product of these two matrices will be each row, transformed into principal-component space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled.dot(pcabh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naturally, sklearn has a shortcut for this!\n",
    "\n",
    "pca = PCA(n_components=3)                       # Check out how `n_components` works\n",
    "\n",
    "X_new = pca.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check out the explained variance\n",
    "\n",
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The ratio is often more informative\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36138659, -0.08452251,  0.85667061,  0.3582892 ],\n",
       "       [ 0.65658877,  0.73016143, -0.17337266, -0.07548102],\n",
       "       [-0.58202985,  0.59791083,  0.07623608,  0.54583143],\n",
       "       [-0.31548719,  0.3197231 ,  0.47983899, -0.75365743]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also check out the Principal Components themselves\n",
    "\n",
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
