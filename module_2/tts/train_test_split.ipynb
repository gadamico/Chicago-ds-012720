{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Test Split\n",
    "\n",
    "> Best practice is to train test split your data right away.  We will be moving towards treating the test sample as a hold out sample that is not touched until you want to test your final model.\n",
    "\n",
    "> To achieve that, you will want to test out different variations of model only on your train set. Doing so takes requires some careful coding.  It may also include K-Folds, which is shown at the bottom of this notebook.\n",
    "\n",
    "> Since comfort with train-test split is required for even more thorough cross-validation, for this project, it is acceptable to do a single TTS.  Fit the model on the train, validate on the test to see if it is overfitting.  \n",
    "\n",
    "> In the back of your mind, however, know that if you are tuning your model by predicting on your test set, you are creating a biased model which has, in a way, seen the test data before final validation.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Binarizer, LabelBinarizer\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Carseats.csv')\n",
    "y = df.Sales\n",
    "X = df.drop('Sales', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the dataset is small, I will use a test size on the small side (.2 instead of .3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Use a standard scaler to put all numeric values on the same scale. We want to fit standard scaler to the train set, and then apply the scaler to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "\n",
    "X_train_num = X_train.select_dtypes(exclude='object')\n",
    "\n",
    "# Standard scaler will strip our column names and index\n",
    "# Save them here to re-apply in the future\n",
    "\n",
    "X_train_num_columns = X_train_num.columns\n",
    "X_train_num_index = X_train_num.index\n",
    "\n",
    "X_train_num = pd.DataFrame(ss.fit_transform(X_train_num))\n",
    "X_train_num.columns = X_train_num_columns\n",
    "X_train_num.index = X_train_num_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_obj = X_train.select_dtypes(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmaxbarry/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/johnmaxbarry/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Convert Urban and US to binary\n",
    "urb_bin = LabelBinarizer()\n",
    "X_train_obj['Urban'] = urb_bin.fit_transform(X_train_obj['Urban'])\n",
    "\n",
    "us_bin = LabelBinarizer()\n",
    "X_train_obj['US'] = us_bin.fit_transform(X_train_obj['US'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "shelve_dum = pd.get_dummies(X_train_obj['ShelveLoc'])\n",
    "shelve_dum.drop('Bad', axis=1, inplace=True)\n",
    "\n",
    "X_train_processed = X_train_num.join(shelve_dum)\n",
    "X_train_processed = X_train_processed.join(X_train_obj[['Urban', 'US']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We want to fit our linear regression on the train set.  Do not fit on the test set.  \n",
    "> Once we fit, we get our score on the train set.<br>\n",
    "> If the R2 is low, then we have high bias.<br>\n",
    "> If it is high, it is low bias.<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8658420026331486\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_processed, y_train)\n",
    "print(lr.score(X_train_processed, y_train)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnmaxbarry/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  del sys.path[0]\n",
      "/Users/johnmaxbarry/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Now repeat for test set\n",
    "X_test_num = X_test.select_dtypes(exclude='object')\n",
    "X_test_num_columns = X_test_num.columns\n",
    "X_test_num_index = X_test_num.index\n",
    "\n",
    "X_test_num = pd.DataFrame(ss.transform(X_test_num))\n",
    "X_test_num.columns = X_test_num_columns\n",
    "X_test_num.index = X_test_num_index\n",
    "\n",
    "X_test_obj = X_test.select_dtypes(include='object')\n",
    "\n",
    "# Convert Urban and US to binary\n",
    "X_test_obj['Urban'] = urb_bin.transform(X_test_obj['Urban'])\n",
    "\n",
    "us_bin = LabelBinarizer()\n",
    "X_test_obj['US'] = urb_bin.transform(X_test_obj['US'])\n",
    "\n",
    "shelve_dum = pd.get_dummies(X_test_obj['ShelveLoc'])\n",
    "shelve_dum.drop('Bad', axis=1, inplace=True)\n",
    "\n",
    "X_test_processed = X_test_num.join(shelve_dum)\n",
    "X_test_processed = X_test_processed.join(X_test_obj[['Urban', 'US']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We compare our train score to our test score.  If there is a significant decline between train and test, that means the model is **overfit**.  <br>\n",
    "> In other words, our model has **high variance**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8658420026331486\n",
      "0.8892712759554209\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train_processed, y_train)\n",
    "print(lr.score(X_train_processed, y_train)) \n",
    "print(lr.score(X_test_processed, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus: K-Folds\n",
    "_Do not attempt until you have train_test_split down._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> For an even more thorough validation, we use k-folds on the train set.\n",
    "When you are building a model, you do not want to tune your model with knowledge of the test set.  \n",
    "\n",
    "> But, how do you then prevent against over-fitting if the way you see if a model is overfit is by comparing train and test scores? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.852491264515875\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "\n",
    "test_r2 = []\n",
    "for train_ind, val_ind in kf.split(X_train_processed, y_train):\n",
    "    X_tt, y_tt = X_train_processed.iloc[train_ind], y_train.iloc[train_ind]\n",
    "    X_val, y_val = X_train_processed.iloc[val_ind], y_train.iloc[val_ind]\n",
    "    lr.fit(X_tt, y_tt)\n",
    "    test_r2.append(lr.score(X_val, y_val))\n",
    "\n",
    "print(sum(test_r2)/len(test_r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
